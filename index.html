<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_c3m3d4lhbmd7-0{list-style-type:none}ul.lst-kix_tqav6y84cgtf-7{list-style-type:none}ul.lst-kix_tqav6y84cgtf-6{list-style-type:none}ul.lst-kix_tqav6y84cgtf-8{list-style-type:none}ul.lst-kix_tvepeaw59b9g-2{list-style-type:none}ul.lst-kix_tqav6y84cgtf-3{list-style-type:none}ul.lst-kix_tvepeaw59b9g-1{list-style-type:none}ul.lst-kix_tqav6y84cgtf-2{list-style-type:none}ul.lst-kix_tvepeaw59b9g-0{list-style-type:none}ul.lst-kix_tqav6y84cgtf-5{list-style-type:none}ul.lst-kix_tqav6y84cgtf-4{list-style-type:none}.lst-kix_c3m3d4lhbmd7-7>li:before{content:"\0025cb   "}ul.lst-kix_tqav6y84cgtf-1{list-style-type:none}ul.lst-kix_tqav6y84cgtf-0{list-style-type:none}.lst-kix_c3m3d4lhbmd7-8>li:before{content:"\0025a0   "}.lst-kix_c3m3d4lhbmd7-2>li:before{content:"\0025a0   "}.lst-kix_c3m3d4lhbmd7-4>li:before{content:"\0025cb   "}.lst-kix_c3m3d4lhbmd7-3>li:before{content:"\0025cf   "}ul.lst-kix_tvepeaw59b9g-6{list-style-type:none}ul.lst-kix_tvepeaw59b9g-5{list-style-type:none}ul.lst-kix_tvepeaw59b9g-4{list-style-type:none}ul.lst-kix_tvepeaw59b9g-3{list-style-type:none}.lst-kix_c3m3d4lhbmd7-6>li:before{content:"\0025cf   "}ul.lst-kix_tvepeaw59b9g-8{list-style-type:none}ul.lst-kix_tvepeaw59b9g-7{list-style-type:none}.lst-kix_c3m3d4lhbmd7-5>li:before{content:"\0025a0   "}ul.lst-kix_c3m3d4lhbmd7-2{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-1{list-style-type:none}.lst-kix_c3m3d4lhbmd7-0>li:before{content:"\0025cf   "}ul.lst-kix_c3m3d4lhbmd7-4{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-3{list-style-type:none}.lst-kix_c3m3d4lhbmd7-1>li:before{content:"\0025cb   "}ul.lst-kix_c3m3d4lhbmd7-6{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-5{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-8{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-7{list-style-type:none}.lst-kix_mqbepa7onuvy-4>li:before{content:"\0025cb   "}.lst-kix_mqbepa7onuvy-6>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-3>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-7>li:before{content:"\0025cb   "}.lst-kix_mqbepa7onuvy-0>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-2>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-8>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-5>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-1>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-6>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-8>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-7>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-8>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-6>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-7>li:before{content:"\0025cb   "}.lst-kix_5h1v5tj214r7-5>li:before{content:"\0025a0   "}.lst-kix_tqav6y84cgtf-8>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-5>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-2>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-3>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-1>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-7>li:before{content:"\0025cb   "}.lst-kix_m0x3ng30pxgy-0>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-0>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-4>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-6>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-3>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-5>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-1>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-8>li:before{content:"\0025a0   "}.lst-kix_tqav6y84cgtf-4>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-4>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-1>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-2>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-3>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-2>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-0>li:before{content:"\0025cf   "}.lst-kix_ag06ygptcqj8-1>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-0>li:before{content:"\0025cf   "}ul.lst-kix_5h1v5tj214r7-4{list-style-type:none}ul.lst-kix_5h1v5tj214r7-5{list-style-type:none}ul.lst-kix_5h1v5tj214r7-2{list-style-type:none}.lst-kix_vco7omwref9g-5>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-7>li:before{content:"\0025cb   "}ul.lst-kix_5h1v5tj214r7-3{list-style-type:none}ul.lst-kix_5h1v5tj214r7-8{list-style-type:none}ul.lst-kix_5h1v5tj214r7-6{list-style-type:none}.lst-kix_vco7omwref9g-2>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-6>li:before{content:"\0025cf   "}ul.lst-kix_5h1v5tj214r7-7{list-style-type:none}.lst-kix_vco7omwref9g-1>li:before{content:"\0025cb   "}ul.lst-kix_5h1v5tj214r7-0{list-style-type:none}ul.lst-kix_5h1v5tj214r7-1{list-style-type:none}.lst-kix_vco7omwref9g-0>li:before{content:"\0025cf   "}.lst-kix_vco7omwref9g-8>li:before{content:"\0025a0   "}.lst-kix_98axzw46idia-7>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-6>li:before{content:"\0025cf   "}.lst-kix_98axzw46idia-5>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-7{list-style-type:none}ul.lst-kix_ag06ygptcqj8-8{list-style-type:none}.lst-kix_98axzw46idia-4>li:before{content:"\0025cb   "}.lst-kix_vco7omwref9g-4>li:before{content:"\0025cb   "}.lst-kix_m0x3ng30pxgy-2>li:before{content:"\0025a0   "}ul.lst-kix_ag06ygptcqj8-3{list-style-type:none}ul.lst-kix_ag06ygptcqj8-4{list-style-type:none}.lst-kix_98axzw46idia-1>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-2>li:before{content:"\0025a0   "}.lst-kix_m0x3ng30pxgy-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-5{list-style-type:none}ul.lst-kix_ag06ygptcqj8-6{list-style-type:none}.lst-kix_m0x3ng30pxgy-4>li:before{content:"\0025cb   "}ul.lst-kix_ag06ygptcqj8-0{list-style-type:none}.lst-kix_98axzw46idia-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-1{list-style-type:none}ul.lst-kix_ag06ygptcqj8-2{list-style-type:none}.lst-kix_m0x3ng30pxgy-6>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-5>li:before{content:"\0025a0   "}.lst-kix_m0x3ng30pxgy-7>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-0>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-8>li:before{content:"\0025a0   "}ul.lst-kix_mqbepa7onuvy-7{list-style-type:none}ul.lst-kix_mqbepa7onuvy-8{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-7{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-8{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-5{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-6{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-3{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-4{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-1{list-style-type:none}ul.lst-kix_vco7omwref9g-3{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-2{list-style-type:none}ul.lst-kix_vco7omwref9g-2{list-style-type:none}ul.lst-kix_vco7omwref9g-1{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-0{list-style-type:none}ul.lst-kix_vco7omwref9g-0{list-style-type:none}.lst-kix_tvepeaw59b9g-8>li:before{content:"\0025a0   "}.lst-kix_tvepeaw59b9g-3>li:before{content:"\0025cf   "}ul.lst-kix_98axzw46idia-4{list-style-type:none}ul.lst-kix_98axzw46idia-3{list-style-type:none}ul.lst-kix_98axzw46idia-2{list-style-type:none}ul.lst-kix_98axzw46idia-1{list-style-type:none}.lst-kix_tvepeaw59b9g-1>li:before{content:"\0025cb   "}.lst-kix_tvepeaw59b9g-5>li:before{content:"\0025a0   "}ul.lst-kix_98axzw46idia-8{list-style-type:none}ul.lst-kix_98axzw46idia-7{list-style-type:none}.lst-kix_tvepeaw59b9g-0>li:before{content:"\0025cf   "}.lst-kix_tvepeaw59b9g-4>li:before{content:"\0025cb   "}ul.lst-kix_98axzw46idia-6{list-style-type:none}ul.lst-kix_98axzw46idia-5{list-style-type:none}.lst-kix_tvepeaw59b9g-7>li:before{content:"\0025cb   "}ul.lst-kix_vco7omwref9g-8{list-style-type:none}ul.lst-kix_98axzw46idia-0{list-style-type:none}ul.lst-kix_vco7omwref9g-7{list-style-type:none}ul.lst-kix_vco7omwref9g-6{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_tvepeaw59b9g-6>li:before{content:"\0025cf   "}ul.lst-kix_vco7omwref9g-5{list-style-type:none}ul.lst-kix_vco7omwref9g-4{list-style-type:none}ul.lst-kix_mqbepa7onuvy-1{list-style-type:none}ul.lst-kix_mqbepa7onuvy-2{list-style-type:none}ul.lst-kix_mqbepa7onuvy-0{list-style-type:none}ul.lst-kix_mqbepa7onuvy-5{list-style-type:none}ul.lst-kix_mqbepa7onuvy-6{list-style-type:none}.lst-kix_tvepeaw59b9g-2>li:before{content:"\0025a0   "}ul.lst-kix_mqbepa7onuvy-3{list-style-type:none}ul.lst-kix_mqbepa7onuvy-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c1{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c5{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c15{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c6{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c16{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c14{background-color:#ffffff;font-size:12pt}.c0{padding:0;margin:0}.c3{color:inherit;text-decoration:inherit}.c13{margin-left:108pt;padding-left:0pt}.c7{background-color:#ffff00}.c8{font-style:italic}.c11{font-size:14pt}.c10{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c16 doc-content"><div><p class="c9 c10"><span class="c2"></span></p></div><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 45.33px;"><img alt="" src="images/image1.gif" style="width: 624.00px; height: 45.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span>The AI and Systems Co-Design team at </span><span>Meta (formerly known as Facebook), led by </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://tangchq74.github.io/&amp;sa=D&amp;source=editors&amp;ust=1728629532871745&amp;usg=AOvVaw1AwST97auIHGgGpdahs__k">Chunqiang Tang (a.k.a. CQ Tang)</a></span><span>, consists of over 100 employees, mostly PhDs, including many world-class </span><span class="c6"><a class="c3" href="#id.ntu08f6dqd4i">research scientists and engineers</a></span><span class="c2">. We conduct interdisciplinary research and development across hardware, software, and AI, as reflected in our team name &ldquo;co-design.&rdquo;</span></p><ul class="c0 lst-kix_vco7omwref9g-0 start"><li class="c5 li-bullet-0"><span>We own the company&rsquo;s overall strategy for exploring innovative hardware technologies for CPUs, GPUs, storage and Meta&rsquo;s custom AI chips, and productionizing them in Meta&rsquo;s hyperscale fleet of O(1,000,000) servers and O(100,000) GPUs, powering all Meta products such as Facebook, Instagram, and </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=http://meta.ai&amp;sa=D&amp;source=editors&amp;ust=1728629532872338&amp;usg=AOvVaw3oPXB5fsblFpOcKuWq4ASi">meta.ai</a></span><span class="c2">.</span></li><li class="c5 li-bullet-0"><span class="c2">We apply novel software optimizations across the whole stack&mdash;from ML models and applications to the Linux kernel&mdash;to achieve optimal performance on the hardware.</span></li><li class="c5 li-bullet-0"><span class="c2">We develop innovative AI technologies for large language models (Llama), ranking, and recommendation.</span></li></ul><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span>Overall, our work largely corresponds to the research communities of hardware architecture (ISCA, ASPLOS), systems for ML (MLSys and ML-related parts of SOSP, OSDI, SIGCOMM, NSDI), ML (NeurIPS, ICML, ICLR) and supercomputing (SC, ICS). Here are selected publications that highlight our work in diverse </span><span>areas</span><span class="c2">.</span></p><p class="c9 c10"><span class="c2 c7"></span></p><ul class="c0 lst-kix_c3m3d4lhbmd7-0 start"><li class="c5 li-bullet-0"><span class="c2">AI chip and server design</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=http://firoozshahian.com/publications/3579371.3589348.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532873243&amp;usg=AOvVaw33AfiAq8zFtJGcUhYdZxU4">MTIA: First Generation Silicon Targeting Meta&rsquo;s Recommendation Systems</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/&amp;sa=D&amp;source=editors&amp;ust=1728629532873539&amp;usg=AOvVaw09VbYr-MojunHaSOhi1bPE">The Grand Teton AI Server</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">Systems for AI</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&amp;sa=D&amp;source=editors&amp;ust=1728629532873907&amp;usg=AOvVaw2-j6MofYOQU_mfOy1RxK6H">Llama 2: Open foundation and fine-tuned chat models</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-2 start"><li class="c9 c13 li-bullet-0"><span>Our contributions include </span><span>re-architecturing Llama&rsquo;s training infrastructure, transitioning from a research environment to Meta&rsquo;s hyperscale production private cloud.</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/the-llama-3-herd-of-models/&amp;sa=D&amp;source=editors&amp;ust=1728629532874478&amp;usg=AOvVaw02K7zjQc4bs4aDXEc3_Whg">The Llama 3 Herd of Models</a></span><span class="c2">: </span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-2 start"><li class="c9 c13 li-bullet-0"><span>Our contributions include much of the work described in the paper&rsquo;s Section 3.3 </span><span class="c8">&ldquo;Infrastructure, Scaling, and Efficiency&rdquo; , </span><span>Section 6 &ldquo;</span><span class="c8">Inference</span><span>&rdquo;, and Section 7.3</span><span class="c8">&nbsp;&ldquo;Model Scaling.&rdquo;</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2104.05158&amp;sa=D&amp;source=editors&amp;ust=1728629532875216&amp;usg=AOvVaw3H5E5WHi7dyO0DAi9VgAJP">Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2304.11277&amp;sa=D&amp;source=editors&amp;ust=1728629532875557&amp;usg=AOvVaw1FrrakZ_9zY1d5VY9kJ21g">PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">ML models and kernels</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/1906.00091&amp;sa=D&amp;source=editors&amp;ust=1728629532876036&amp;usg=AOvVaw27EJE37igchjGBxRvvaFs2">Deep Learning Recommendation Model for Personalization and Recommendation Systems</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.02545&amp;sa=D&amp;source=editors&amp;ust=1728629532876396&amp;usg=AOvVaw3JehSTsux9p0uGS4WIBrdK">Wukong: Towards a Scaling Law for Large-Scale Recommendation</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2101.05615&amp;sa=D&amp;source=editors&amp;ust=1728629532876762&amp;usg=AOvVaw2wHpNgcEAocj0OJpyne36h">FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">ML numerics, pruning, distillation, and optimizer</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.10537&amp;sa=D&amp;source=editors&amp;ust=1728629532877185&amp;usg=AOvVaw1lI0xNyEB7g5dLc9N8WEWw">Microscaling Data Formats for Deep Learning</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/blog/int4-decoding/&amp;sa=D&amp;source=editors&amp;ust=1728629532877504&amp;usg=AOvVaw0RFsE9vC6rZ4ptJsEs7PHm">INT4 Decoding GQA CUDA Optimizations for LLM Inference</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/&amp;sa=D&amp;source=editors&amp;ust=1728629532877907&amp;usg=AOvVaw2MXPpY6LGu7-uhLuaAZev2">Pruning and Distillation to Enable Llama 3.2 1B and 3B Models Suitable for Mobile Devices</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.linkedin.com/posts/hjmshi_announcing-the-results-of-the-inaugural-algoperf-activity-7224879495734870017-rVHn/&amp;sa=D&amp;source=editors&amp;ust=1728629532878365&amp;usg=AOvVaw1I0flKCzennJ0xz__E-14Y">PyTorch Distributed Shampoo Winning the MLCommon Training Algorithms Competition</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">HPC and collective communication (MPI, NCCL, RCCL)</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.04272&amp;sa=D&amp;source=editors&amp;ust=1728629532878940&amp;usg=AOvVaw3GaPHtKWYHMrVLMfv33_fM">Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2020/08/Training-Deep-Learning-Recommendation-Model-with-Quantized-Collective-Communications-v2.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532879463&amp;usg=AOvVaw30SHsxpoptL_Syr8HdZ4c3">Training Deep Learning Recommendation Model with Quantized Collective Communications</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">Performance benchmarking and projection</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728629532880005&amp;usg=AOvVaw0sYboDGedKMCqu3Qp9FlUk">DCPerf: An open source benchmark suite for hyperscale compute applications</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/&amp;sa=D&amp;source=editors&amp;ust=1728629532880467&amp;usg=AOvVaw2xesVvsgpx2-0vyOt3Cuxn">DLRM: An advanced, open source deep learning recommendation model</a></span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c2">Hardware and software co-design</span></li></ul><ul class="c0 lst-kix_c3m3d4lhbmd7-1 start"><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2206.02878&amp;sa=D&amp;source=editors&amp;ust=1728629532880874&amp;usg=AOvVaw1RRwBl_6wTwMtN4dcHWcbA">TPP: Transparent Page Placement for CXL-Enabled Tiered-Memory</a></span></li><li class="c1 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2019/05/SoftSKU-Optimizing-Server-Architectures-for-Microservice-Diversity-@Scale.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532881345&amp;usg=AOvVaw1bDGTU_Hj8Vt9AYIG-pYSl">SoftSKU: Optimizing Server Architectures for Microservice Diversity @Scale</a></span></li></ul><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span>For the areas mentioned above, we are actively hiring managers, PhDs, and experienced engineers, but we are not hiring new graduates with BS or MS degrees. If interested, please submit your resume </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://2024resumedropco-design.splashthat.com/&amp;sa=D&amp;source=editors&amp;ust=1728629532881753&amp;usg=AOvVaw1e55nGST7v5PI7VAJjaQEX">here</a></span><span class="c2">. If you have questions, please email us at codesignATmetaDOTcom.</span></p><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span>While we excel in and strongly encourage research and publication, our primary focus is on developing cutting-edge innovations in hardware, software, and AI, and directly integrating them into production systems that serve billions of people worldwide. This emphasis on production systems and </span><span class="c8">direct real-world impact </span><span>distinguishes us from traditional research labs that rely on technology transfer for </span><span class="c8">indirect impact</span><span class="c2">. As a result, in addition to advancing research, we deliver foundational impact to the company by driving Meta&rsquo;s hardware strategy to save billions of dollars and directly implementing innovative technologies in flagship products like Llama and Ads ranking models.</span></p><p class="c9 c10"><span class="c2"></span></p><a id="id.ntu08f6dqd4i"></a><p class="c9"><span>To gain a better understanding of who we are, feel free to explore some profiles of our team </span><span>members: </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://tangchq74.github.io/&amp;sa=D&amp;source=editors&amp;ust=1728629532882475&amp;usg=AOvVaw2_kpHOdGjr3qqtdiDree4x">Chunqiang (CQ) Tang</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D8xbO51UAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532882710&amp;usg=AOvVaw3xlZKqiMWHyUKxviOSP7kp">Pavan Balaji</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DHqGW4HIAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532882936&amp;usg=AOvVaw2HIpJcRkup5hN1jh2uMDhB">Amar Phanishayee</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3Dp5h2zh8AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532883199&amp;usg=AOvVaw3n0HxvII9qXybi-w9A81F2">Maxim Naumov</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://sites.google.com/site/jongsoopark/home&amp;sa=D&amp;source=editors&amp;ust=1728629532883444&amp;usg=AOvVaw35xwA5Jwv-vHN845l-Vy7V">Jongsoo Park</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DeOyDnQYAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728629532883682&amp;usg=AOvVaw2w7mbSx9-zbmWYkjEGyypK">Changkyu Kim</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DyxUD8q4AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532883946&amp;usg=AOvVaw2_CEfAeq23jgX-h6ooBuph">Doe Hyun Yoon</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DyUXXPwYAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728629532884212&amp;usg=AOvVaw3lWQGAdTeOZmp_TWyWHNMG">Satish Nadathur</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D8rbsmO0AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532884460&amp;usg=AOvVaw2-KqsV5QPZpiWeSykBfF7N">Abhishek Dhanotia</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DKpnlsFwAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532884744&amp;usg=AOvVaw0AL5RLO103Zc1dqXRq9ddv">Joel Coburn</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D6PyfjT4AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532884992&amp;usg=AOvVaw0dRMvvD_GIopxqZvWGtRwV">Ehsan K. Ardestani</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DCe2uZUYAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532885250&amp;usg=AOvVaw2Ob_Pl0eJIErXc7nltzxXe">Bangsheng Tang</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DmD2TUGQAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532885496&amp;usg=AOvVaw3ZhKLihCrWcesEEzc9njBh">Mustafa Ozdal</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D5h4eSNQAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728629532885738&amp;usg=AOvVaw0pIG1pvahZITmiRuKZBVeD">Jianyu Huang</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dblp.org/pid/92/5162.html&amp;sa=D&amp;source=editors&amp;ust=1728629532886001&amp;usg=AOvVaw3tN31AIamCk5eiUX9kx4Kh">Wenyin Fu</a></span><span>, </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DnFONGREAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728629532886252&amp;usg=AOvVaw1cFfVuGPJ1bmlBOH-c4_M6">Jayneel Gandhi</a></span></p><h2 class="c15" id="h.r2quqn5ki81e"><span>Open Source Projects</span></h2><p class="c9"><span class="c2">Please add links to open source projects that we contributed to.</span></p><ul class="c0 lst-kix_tqav6y84cgtf-0 start"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728629532886951&amp;usg=AOvVaw1IId4WwXiQaMOCQVN2l1-4">DCPerf: An open source benchmark suite for hyperscale compute applications</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/&amp;sa=D&amp;source=editors&amp;ust=1728629532887420&amp;usg=AOvVaw32-UYv2Azj8_oFIlZoYR4M">DLRM: An advanced, open source deep learning recommendation model</a></span></li><li class="c5 li-bullet-0"><span>ML kernels: </span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728629532887736&amp;usg=AOvVaw3fBdI0Lmj-oVNshXP9RBKC">FBGEMM (Facebook GEneral Matrix Multiplication) and FBGEMM_GPU(</a></span><span class="c6 c14"><a class="c3" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728629532887920&amp;usg=AOvVaw1SkZYvpkWjZhxi7U2GVBrS">FBGEMM GPU Kernels Library</a></span><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728629532888093&amp;usg=AOvVaw212Vycy9FmRMdfUuwbZFVI">) </a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/optimizers/blob/main/distributed_shampoo/README.md&amp;sa=D&amp;source=editors&amp;ust=1728629532888461&amp;usg=AOvVaw2KrCG-UJaPchhh0rY8d5CU">Pytorch distributed Shampoo optimizer</a></span></li></ul><h2 class="c15" id="h.w9asws8yn66t"><span>Selected Publications</span></h2><p class="c9"><span class="c12 c11">2024</span></p><ul class="c0 lst-kix_mqbepa7onuvy-0 start"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.21783&amp;sa=D&amp;source=editors&amp;ust=1728629532889055&amp;usg=AOvVaw3E7t8lpndd-8kaNLY6E5ya">The Llama 3 Herd of Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.04272&amp;sa=D&amp;source=editors&amp;ust=1728629532889383&amp;usg=AOvVaw1bfSddHJMbqdmzcgCyvVcd">Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.02545&amp;sa=D&amp;source=editors&amp;ust=1728629532889767&amp;usg=AOvVaw2uLPgv4x-2nkSzro4VuRCM">Wukong: Towards a Scaling Law for Large-Scale Recommendation</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://proceedings.mlsys.org/paper_files/paper/2024/file/78834433edc3291f4c6cbbd2759324db-Paper-Conference.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532890189&amp;usg=AOvVaw0vNThZZy0n419hG2F64_HF">Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large Scale Recommendation</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.linkedin.com/posts/hjmshi_announcing-the-results-of-the-inaugural-algoperf-activity-7224879495734870017-rVHn/&amp;sa=D&amp;source=editors&amp;ust=1728629532890571&amp;usg=AOvVaw3CiVZSJ9MmuW-bVjvKCzvG">PyTorch Distributed Shampoo Winning the MLCommon Training Algorithms Competition</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.1145/3589335.3648304&amp;sa=D&amp;source=editors&amp;ust=1728629532890916&amp;usg=AOvVaw2BeIqXuZ5op3vv2akuc43X">Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.14377&amp;sa=D&amp;source=editors&amp;ust=1728629532891305&amp;usg=AOvVaw13qeldcsIU62X3YDKCJA52">CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.usenix.org/system/files/osdi24-choudhury.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532891645&amp;usg=AOvVaw2XPSF5jjJ_Dz62fiyDfFrf">MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.usenix.org/system/files/nsdi24-matam.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532892026&amp;usg=AOvVaw3GGxPfniwbwqXMWyV1Xos7">QuickUpdate: a Real-Time Personalization System for Large-Scale Recommendation Model</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3640457.3688037&amp;sa=D&amp;source=editors&amp;ust=1728629532892376&amp;usg=AOvVaw0_yyTyZSC2iX1oGJksDbEK">Toward 100TB Recommendation Models With Embedding Offloading</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728629532892784&amp;usg=AOvVaw1F2xGsWRzkNZILxrp5vT_T">DCPerf: An open source benchmark suite for hyperscale compute applications </a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3617232.3624853&amp;sa=D&amp;source=editors&amp;ust=1728629532893114&amp;usg=AOvVaw2KzhAGbGM09XMMlXX_afaZ">Expanding Datacenter Capacity with DVFS Boosting: A safe and scalable deployment experience</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.1145/3589335.3648304&amp;sa=D&amp;source=editors&amp;ust=1728629532893468&amp;usg=AOvVaw16QDt_gQZQ8QIVpX1QtH41">Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale</a></span></li></ul><p class="c9 c10"><span class="c11 c12"></span></p><p class="c9"><span class="c11">2023</span></p><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=http://firoozshahian.com/publications/3579371.3589348.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532894082&amp;usg=AOvVaw0qY0gfDDvj9XcUbKz0o47K">MTIA: First Generation Silicon Targeting Meta&rsquo;s Recommendation Systems</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.10537&amp;sa=D&amp;source=editors&amp;ust=1728629532894410&amp;usg=AOvVaw3MpuNFdXWA0c9aqTZxezRf">Microscaling Data Formats for Deep Learning</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2302.08007&amp;sa=D&amp;source=editors&amp;ust=1728629532894769&amp;usg=AOvVaw20OT4sjJGvPdio79F5Hvoz">Shared Microexponents: A Little Shifting Goes a Long Way</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2206.02878&amp;sa=D&amp;source=editors&amp;ust=1728629532895086&amp;usg=AOvVaw2aEiDKNMp4wUuzEAbR-kkS">TPP: Transparent Page Placement for CXL-Enabled Tiered-Memory</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3579371.3589079&amp;sa=D&amp;source=editors&amp;ust=1728629532895441&amp;usg=AOvVaw3Y_k8xpIJqRAe8ENM1nmLM">Contiguitas: The Pursuit of Physical Memory Contiguity in Datacenters</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3579371.3589072&amp;sa=D&amp;source=editors&amp;ust=1728629532895781&amp;usg=AOvVaw3OqTXRaSxF1fAfR6Mqmqvy">Mystique: Enabling Accurate and Scalable Generation of Production AI Benchmarks</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2211.05239&amp;sa=D&amp;source=editors&amp;ust=1728629532896090&amp;usg=AOvVaw2VRF2CBBX33Uxo5y-aDwQI">RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.usenix.org/conference/osdi23/presentation/lai&amp;sa=D&amp;source=editors&amp;ust=1728629532896427&amp;usg=AOvVaw0CVfZvywH_CGDdOjhZH1Mn">AdaEmbed: Adaptive Embedding for Large-Scale Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&amp;sa=D&amp;source=editors&amp;ust=1728629532896791&amp;usg=AOvVaw3nEh5MGsW3bi4ZhHed8JgW">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/document/10158161&amp;sa=D&amp;source=editors&amp;ust=1728629532897110&amp;usg=AOvVaw3QPf94ro_xeRlh4b7v-xnv">Characterization of Data Compression in Datacenters, </a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3575693.3575751&amp;sa=D&amp;source=editors&amp;ust=1728629532897494&amp;usg=AOvVaw3xq1FADSMXLxD26JByDgjE">Ditto: End-to-End Application Cloning for Networked Cloud Services,</a></span><span class="c2">&nbsp;</span></li></ul><p class="c9 c10"><span class="c12 c11"></span></p><p class="c9"><span class="c11">2022</span></p><ul class="c0 lst-kix_5h1v5tj214r7-0 start"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2104.05158&amp;sa=D&amp;source=editors&amp;ust=1728629532897982&amp;usg=AOvVaw3UX291KPAKtFR8lfTGBw8J">Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2203.11014&amp;sa=D&amp;source=editors&amp;ust=1728629532898346&amp;usg=AOvVaw0yxdj0H0r35ehbMTVGTE4Z">DHEN: A deep and hierarchical ensemble network for large-scale click-through rate prediction</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://tangchq74.github.io/TMO-ASPLOS22.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532898692&amp;usg=AOvVaw0qgEHv9dUFmRcXSTAgrBvm">TMO: Transparent Memory Offloading in Datacenters</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.lockshaw.io/static/unity.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532899016&amp;usg=AOvVaw1E6B6_5z1vCdojdNFhvoB7">Unity: A Unified Graph Representation and Runtime for Distributed DNN Training</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.usenix.org/system/files/nsdi22-paper-eisenman.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532899385&amp;usg=AOvVaw3kDW9RQRpVD6B2oR5_VegN">Check-N-Run: a Checkpointing System for Training Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/9912130&amp;sa=D&amp;source=editors&amp;ust=1728629532899707&amp;usg=AOvVaw3oaIcYD-voJ-0w8ExIMa3X">Supporting Massive DLRM Inference through Software Defined Memory</a></span></li></ul><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span class="c11">2021</span></p><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2101.05615&amp;sa=D&amp;source=editors&amp;ust=1728629532900208&amp;usg=AOvVaw0KIFcrEBhRTjV7tW5ZdzeL">FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/9435938&amp;sa=D&amp;source=editors&amp;ust=1728629532900539&amp;usg=AOvVaw1_IiATdgAPtMnDpkgFV3v2">Low-Precision Hardware Architectures Meet Recommendation Model Inference at Scale</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2103.00130&amp;sa=D&amp;source=editors&amp;ust=1728629532900861&amp;usg=AOvVaw2AGrYQI2sAHG2pI76khrIo">Efficient Soft-Error Detection for Low-precision Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2107.04140.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532901171&amp;usg=AOvVaw3i2tV5Xypg9WMXioYT8MQB">First-Generation Inference Accelerator Deployment at Facebook</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/stamp/stamp.jsp?tp%3D%26arnumber%3D9390361&amp;sa=D&amp;source=editors&amp;ust=1728629532901499&amp;usg=AOvVaw1pbSzk-Nc4woniUY2Dlp1b">Understanding Acceleration Opportunities at Hyperscale</a></span><span class="c2">, </span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://www.usenix.org/conference/atc21/presentation/kassa&amp;sa=D&amp;source=editors&amp;ust=1728629532901846&amp;usg=AOvVaw2akMSbeDit5vaV1RN06ePQ">Improving Performance of Flash Based Key-Value Stores Using Storage Class Memory as a Volatile Memory Extension,</a></span></li></ul><p class="c9 c10"><span class="c2"></span></p><p class="c9"><span class="c11">2020</span></p><ul class="c0 lst-kix_m0x3ng30pxgy-0 start"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2020/08/Training-Deep-Learning-Recommendation-Model-with-Quantized-Collective-Communications-v2.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532902503&amp;usg=AOvVaw3jhCMIMMUvFRpeP3WvvIke">Training Deep Learning Recommendation Model with Quantized Collective Communications</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2010.11305&amp;sa=D&amp;source=editors&amp;ust=1728629532902822&amp;usg=AOvVaw3rcs7FPcv-wXaICGyMS6MN">Mixed-Precision Embedding Using a Cache</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2020/11/18/open-source/fiosynth/&amp;sa=D&amp;source=editors&amp;ust=1728629532903172&amp;usg=AOvVaw3WYU3GADvOuFRZC3aGIdSu">FioSynth: A representative I/O benchmark and data visualizer for data center workloads,</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://engineering.fb.com/2020/05/11/data-center-engineering/accelerometer-and-softsku/&amp;sa=D&amp;source=editors&amp;ust=1728629532903536&amp;usg=AOvVaw1HT9uOgwdnV4xCDuXzZBGz">Accelerometer and SoftSKU: Improving hardware platform performance for diverse microservices</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/publications/accelerometer-understanding-acceleration-opportunities-for-data-center-overheads-at-hyperscale/&amp;sa=D&amp;source=editors&amp;ust=1728629532903980&amp;usg=AOvVaw111tjZgyuQlPfDafIieCYU">Accelerometer: Understanding Acceleration Opportunities for Data Center Overheads at Hyperscale</a></span></li></ul><p class="c9 c10"><span class="c12 c11"></span></p><p class="c9"><span class="c11">2019</span></p><ul class="c0 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/1906.00091&amp;sa=D&amp;source=editors&amp;ust=1728629532904520&amp;usg=AOvVaw0mw-cR6bsXoX62vZHvMaE3">Deep Learning Recommendation Model for Personalization and Recommendation Systems</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2019/05/SoftSKU-Optimizing-Server-Architectures-for-Microservice-Diversity-@Scale.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532904991&amp;usg=AOvVaw1LYoEkW46ZHCBt4f3Bq7PN">SoftSKU: Optimizing Server Architectures for Microservice Diversity @Scale</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/1905.12322&amp;sa=D&amp;source=editors&amp;ust=1728629532905315&amp;usg=AOvVaw1yDu3CuBKld9IsGUcoI_B0">A Study of BFLOAT16 for Deep Learning Training</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/1911.02079&amp;sa=D&amp;source=editors&amp;ust=1728629532905614&amp;usg=AOvVaw2ccMdfP0A7J4Yhf0to7Gsz">Post-Training 4-bit Quantization of Embedding Tables</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://proceedings.mlsys.org/paper_files/paper/2019/file/d59a1dc497cf2773637256f50f492723-Paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1728629532906033&amp;usg=AOvVaw3gdM0bCKhhmVp0U2cVJ-sh">Bandana: Using Non-Volatile Memory for Storing Deep Learning Models</a></span></li><li class="c5 li-bullet-0"><span class="c6"><a class="c3" href="https://www.google.com/url?q=https://research.fb.com/publications/whos-afraid-of-uncorrectable-bit-errors-online-recovery-of-flash-errors-with-distributed-redundancy/&amp;sa=D&amp;source=editors&amp;ust=1728629532906460&amp;usg=AOvVaw3JYfW_gt5cId_NpAXSyvo6">Who&#39;s Afraid of Uncorrectable Bit Errors? Online Recovery of Flash Errors with Distributed Redundancy</a></span></li></ul><h2 class="c15" id="h.b6jfprpi5c7e"><span class="c4">NO NEED TO GO BACK TO 2018</span></h2><div><p class="c9 c10"><span class="c2"></span></p></div></body></html>