<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_c3m3d4lhbmd7-0{list-style-type:none}ul.lst-kix_tqav6y84cgtf-7{list-style-type:none}ul.lst-kix_tqav6y84cgtf-6{list-style-type:none}ul.lst-kix_tqav6y84cgtf-8{list-style-type:none}ul.lst-kix_tvepeaw59b9g-2{list-style-type:none}ul.lst-kix_tqav6y84cgtf-3{list-style-type:none}ul.lst-kix_tvepeaw59b9g-1{list-style-type:none}ul.lst-kix_tqav6y84cgtf-2{list-style-type:none}ul.lst-kix_tvepeaw59b9g-0{list-style-type:none}ul.lst-kix_tqav6y84cgtf-5{list-style-type:none}ul.lst-kix_tqav6y84cgtf-4{list-style-type:none}.lst-kix_c3m3d4lhbmd7-7>li:before{content:"\0025cb   "}ul.lst-kix_tqav6y84cgtf-1{list-style-type:none}ul.lst-kix_tqav6y84cgtf-0{list-style-type:none}.lst-kix_c3m3d4lhbmd7-8>li:before{content:"\0025a0   "}.lst-kix_c3m3d4lhbmd7-2>li:before{content:"\0025a0   "}.lst-kix_c3m3d4lhbmd7-4>li:before{content:"\0025cb   "}.lst-kix_c3m3d4lhbmd7-3>li:before{content:"\0025cf   "}ul.lst-kix_tvepeaw59b9g-6{list-style-type:none}ul.lst-kix_tvepeaw59b9g-5{list-style-type:none}ul.lst-kix_tvepeaw59b9g-4{list-style-type:none}ul.lst-kix_tvepeaw59b9g-3{list-style-type:none}.lst-kix_c3m3d4lhbmd7-6>li:before{content:"\0025cf   "}ul.lst-kix_tvepeaw59b9g-8{list-style-type:none}ul.lst-kix_tvepeaw59b9g-7{list-style-type:none}.lst-kix_c3m3d4lhbmd7-5>li:before{content:"\0025a0   "}ul.lst-kix_c3m3d4lhbmd7-2{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-1{list-style-type:none}.lst-kix_c3m3d4lhbmd7-0>li:before{content:"\0025cf   "}ul.lst-kix_c3m3d4lhbmd7-4{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-3{list-style-type:none}.lst-kix_c3m3d4lhbmd7-1>li:before{content:"\0025cb   "}ul.lst-kix_c3m3d4lhbmd7-6{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-5{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-8{list-style-type:none}ul.lst-kix_c3m3d4lhbmd7-7{list-style-type:none}.lst-kix_mqbepa7onuvy-4>li:before{content:"\0025cb   "}.lst-kix_mqbepa7onuvy-6>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-3>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-7>li:before{content:"\0025cb   "}.lst-kix_mqbepa7onuvy-0>li:before{content:"\0025cf   "}.lst-kix_mqbepa7onuvy-2>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-8>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-5>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-1>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-6>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-8>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-7>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-8>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-6>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-7>li:before{content:"\0025cb   "}.lst-kix_5h1v5tj214r7-5>li:before{content:"\0025a0   "}.lst-kix_tqav6y84cgtf-8>li:before{content:"\0025a0   "}.lst-kix_mqbepa7onuvy-5>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-2>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-3>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-1>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-7>li:before{content:"\0025cb   "}.lst-kix_m0x3ng30pxgy-0>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-0>li:before{content:"\0025cf   "}.lst-kix_5h1v5tj214r7-4>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-6>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-3>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-5>li:before{content:"\0025a0   "}.lst-kix_5h1v5tj214r7-1>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-8>li:before{content:"\0025a0   "}.lst-kix_tqav6y84cgtf-4>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-4>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-1>li:before{content:"\0025cb   "}.lst-kix_ag06ygptcqj8-2>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-3>li:before{content:"\0025cf   "}.lst-kix_tqav6y84cgtf-2>li:before{content:"\0025a0   "}.lst-kix_ag06ygptcqj8-0>li:before{content:"\0025cf   "}.lst-kix_ag06ygptcqj8-1>li:before{content:"\0025cb   "}.lst-kix_tqav6y84cgtf-0>li:before{content:"\0025cf   "}ul.lst-kix_5h1v5tj214r7-4{list-style-type:none}ul.lst-kix_5h1v5tj214r7-5{list-style-type:none}ul.lst-kix_5h1v5tj214r7-2{list-style-type:none}.lst-kix_vco7omwref9g-5>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-7>li:before{content:"\0025cb   "}ul.lst-kix_5h1v5tj214r7-3{list-style-type:none}ul.lst-kix_5h1v5tj214r7-8{list-style-type:none}ul.lst-kix_5h1v5tj214r7-6{list-style-type:none}.lst-kix_vco7omwref9g-2>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-6>li:before{content:"\0025cf   "}ul.lst-kix_5h1v5tj214r7-7{list-style-type:none}.lst-kix_vco7omwref9g-1>li:before{content:"\0025cb   "}ul.lst-kix_5h1v5tj214r7-0{list-style-type:none}ul.lst-kix_5h1v5tj214r7-1{list-style-type:none}.lst-kix_vco7omwref9g-0>li:before{content:"\0025cf   "}.lst-kix_vco7omwref9g-8>li:before{content:"\0025a0   "}.lst-kix_98axzw46idia-7>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-6>li:before{content:"\0025cf   "}.lst-kix_98axzw46idia-5>li:before{content:"\0025a0   "}.lst-kix_vco7omwref9g-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-7{list-style-type:none}ul.lst-kix_ag06ygptcqj8-8{list-style-type:none}.lst-kix_98axzw46idia-4>li:before{content:"\0025cb   "}.lst-kix_vco7omwref9g-4>li:before{content:"\0025cb   "}.lst-kix_m0x3ng30pxgy-2>li:before{content:"\0025a0   "}ul.lst-kix_ag06ygptcqj8-3{list-style-type:none}ul.lst-kix_ag06ygptcqj8-4{list-style-type:none}.lst-kix_98axzw46idia-1>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-2>li:before{content:"\0025a0   "}.lst-kix_m0x3ng30pxgy-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-5{list-style-type:none}ul.lst-kix_ag06ygptcqj8-6{list-style-type:none}.lst-kix_m0x3ng30pxgy-4>li:before{content:"\0025cb   "}ul.lst-kix_ag06ygptcqj8-0{list-style-type:none}.lst-kix_98axzw46idia-3>li:before{content:"\0025cf   "}ul.lst-kix_ag06ygptcqj8-1{list-style-type:none}ul.lst-kix_ag06ygptcqj8-2{list-style-type:none}.lst-kix_m0x3ng30pxgy-6>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-5>li:before{content:"\0025a0   "}.lst-kix_m0x3ng30pxgy-7>li:before{content:"\0025cb   "}.lst-kix_98axzw46idia-0>li:before{content:"\0025cf   "}.lst-kix_m0x3ng30pxgy-8>li:before{content:"\0025a0   "}.lst-kix_qu9w87i2kjte-3>li:before{content:"\0025cf   "}ul.lst-kix_qu9w87i2kjte-6{list-style-type:none}ul.lst-kix_qu9w87i2kjte-5{list-style-type:none}ul.lst-kix_qu9w87i2kjte-4{list-style-type:none}ul.lst-kix_mqbepa7onuvy-7{list-style-type:none}ul.lst-kix_qu9w87i2kjte-3{list-style-type:none}ul.lst-kix_mqbepa7onuvy-8{list-style-type:none}ul.lst-kix_qu9w87i2kjte-2{list-style-type:none}ul.lst-kix_qu9w87i2kjte-1{list-style-type:none}ul.lst-kix_qu9w87i2kjte-0{list-style-type:none}.lst-kix_qu9w87i2kjte-2>li:before{content:"\0025a0   "}.lst-kix_qu9w87i2kjte-6>li:before{content:"\0025cf   "}.lst-kix_qu9w87i2kjte-7>li:before{content:"\0025cb   "}ul.lst-kix_m0x3ng30pxgy-7{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-8{list-style-type:none}.lst-kix_qu9w87i2kjte-1>li:before{content:"\0025cb   "}ul.lst-kix_m0x3ng30pxgy-5{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-6{list-style-type:none}.lst-kix_qu9w87i2kjte-0>li:before{content:"\0025cf   "}.lst-kix_qu9w87i2kjte-8>li:before{content:"\0025a0   "}ul.lst-kix_m0x3ng30pxgy-3{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-4{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-1{list-style-type:none}ul.lst-kix_vco7omwref9g-3{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-2{list-style-type:none}ul.lst-kix_vco7omwref9g-2{list-style-type:none}ul.lst-kix_vco7omwref9g-1{list-style-type:none}ul.lst-kix_m0x3ng30pxgy-0{list-style-type:none}ul.lst-kix_vco7omwref9g-0{list-style-type:none}.lst-kix_tvepeaw59b9g-8>li:before{content:"\0025a0   "}.lst-kix_qu9w87i2kjte-5>li:before{content:"\0025a0   "}.lst-kix_qu9w87i2kjte-4>li:before{content:"\0025cb   "}.lst-kix_tvepeaw59b9g-3>li:before{content:"\0025cf   "}ul.lst-kix_98axzw46idia-4{list-style-type:none}ul.lst-kix_98axzw46idia-3{list-style-type:none}ul.lst-kix_98axzw46idia-2{list-style-type:none}ul.lst-kix_98axzw46idia-1{list-style-type:none}.lst-kix_tvepeaw59b9g-1>li:before{content:"\0025cb   "}.lst-kix_tvepeaw59b9g-5>li:before{content:"\0025a0   "}ul.lst-kix_98axzw46idia-8{list-style-type:none}ul.lst-kix_98axzw46idia-7{list-style-type:none}.lst-kix_tvepeaw59b9g-0>li:before{content:"\0025cf   "}.lst-kix_tvepeaw59b9g-4>li:before{content:"\0025cb   "}ul.lst-kix_98axzw46idia-6{list-style-type:none}ul.lst-kix_98axzw46idia-5{list-style-type:none}.lst-kix_tvepeaw59b9g-7>li:before{content:"\0025cb   "}ul.lst-kix_vco7omwref9g-8{list-style-type:none}ul.lst-kix_98axzw46idia-0{list-style-type:none}ul.lst-kix_vco7omwref9g-7{list-style-type:none}ul.lst-kix_vco7omwref9g-6{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_tvepeaw59b9g-6>li:before{content:"\0025cf   "}ul.lst-kix_vco7omwref9g-5{list-style-type:none}ul.lst-kix_vco7omwref9g-4{list-style-type:none}ul.lst-kix_mqbepa7onuvy-1{list-style-type:none}ul.lst-kix_mqbepa7onuvy-2{list-style-type:none}ul.lst-kix_mqbepa7onuvy-0{list-style-type:none}ul.lst-kix_mqbepa7onuvy-5{list-style-type:none}ul.lst-kix_mqbepa7onuvy-6{list-style-type:none}ul.lst-kix_qu9w87i2kjte-8{list-style-type:none}.lst-kix_tvepeaw59b9g-2>li:before{content:"\0025a0   "}ul.lst-kix_mqbepa7onuvy-3{list-style-type:none}ul.lst-kix_qu9w87i2kjte-7{list-style-type:none}ul.lst-kix_mqbepa7onuvy-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c6{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c5{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c18{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c14{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial"}.c3{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c15{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c1{color:inherit;text-decoration:inherit}.c16{background-color:#ffffff;font-size:12pt}.c11{margin-left:108pt;padding-left:0pt}.c8{padding:0;margin:0}.c17{font-weight:400}.c4{font-size:14pt}.c7{font-style:italic}.c19{font-size:16pt}.c12{background-color:#ffff00}.c10{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c15 doc-content"><div><p class="c2"><span class="c0"></span></p></div><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 45.33px;"><img alt="" src="images/image1.gif" style="width: 624.00px; height: 45.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0"></span></p><p class="c9"><span class="c7 c12">TLDR: We are hiring! Feel free to submit your resume </span><span class="c3 c7 c12"><a class="c1" href="https://www.google.com/url?q=https://2024resumedropco-design.splashthat.com/&amp;sa=D&amp;source=editors&amp;ust=1728884223254424&amp;usg=AOvVaw182M4Flhc3Nhnfm7xsEoOV">here</a></span><span class="c7 c12">&nbsp;or </span><span class="c12">email us at <br></span><span class="c7 c12 c10">codesign AT meta DOT com.</span></p><p class="c2"><span class="c0"></span></p><p class="c9"><span>The AI and Systems Co-Design team at </span><span>Meta (formerly known as Facebook), led by </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://tangchq74.github.io/&amp;sa=D&amp;source=editors&amp;ust=1728884223254793&amp;usg=AOvVaw166KZOagW_4MeMCr4eQult">Chunqiang Tang (a.k.a. CQ Tang)</a></span><span>, consists of over 100 employees, mostly PhDs, including many world-class </span><span class="c3"><a class="c1" href="#id.ntu08f6dqd4i">research scientists and engineers</a></span><span class="c0">. We conduct interdisciplinary research and development across hardware, software, and AI, as reflected in our team name &ldquo;co-design.&rdquo;</span></p><ul class="c8 lst-kix_vco7omwref9g-0 start"><li class="c5 li-bullet-0"><span>We own the company&rsquo;s overall strategy for exploring innovative hardware technologies for CPUs, GPUs, and Meta&rsquo;s custom AI chips, and productionizing them in Meta&rsquo;s hyperscale fleet of O(1,000,000) servers and O(100,000) GPUs, powering all Meta products such as Facebook, Instagram, and </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=http://meta.ai&amp;sa=D&amp;source=editors&amp;ust=1728884223255051&amp;usg=AOvVaw2diU5EL8qsO2JnLI8ft86f">meta.ai</a></span><span class="c0">.</span></li><li class="c5 li-bullet-0"><span class="c0">We apply novel software optimizations across the whole stack&mdash;from ML models and applications to the Linux kernel&mdash;to achieve optimal performance on the hardware.</span></li><li class="c5 li-bullet-0"><span class="c0">We develop innovative AI technologies for large language models (Llama), ranking, and recommendation.</span></li></ul><p class="c2"><span class="c0"></span></p><p class="c9"><span>Overall, our work largely corresponds to the research communities of hardware architecture (ISCA, ASPLOS), systems for ML (MLSys and ML-related parts of SOSP, OSDI, SIGCOMM, NSDI), ML (NeurIPS, ICML, ICLR) and supercomputing (SC, ICS). Here are selected publications that showcase our work in diverse </span><span>areas</span><span class="c0">.</span></p><p class="c2"><span class="c0"></span></p><ul class="c8 lst-kix_c3m3d4lhbmd7-0 start"><li class="c5 li-bullet-0"><span class="c0">AI chip and server design</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=http://firoozshahian.com/publications/3579371.3589348.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223255590&amp;usg=AOvVaw1W9f04smKxWGy2zdOHtSeG">MTIA: First Generation Silicon Targeting Meta&rsquo;s Recommendation Systems</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/&amp;sa=D&amp;source=editors&amp;ust=1728884223255781&amp;usg=AOvVaw0YBr7mx1BbHWh4aSVV3xmR">The Grand Teton AI Server</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">Systems for AI</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&amp;sa=D&amp;source=editors&amp;ust=1728884223256002&amp;usg=AOvVaw0VPtjeQPM-gsFe54AALQJc">Llama 2: Open foundation and fine-tuned chat models</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-2 start"><li class="c9 c11 li-bullet-0"><span class="c0">Our contributions include re-architecting Llama&#39;s training infrastructure and transitioning it from a research environment to Meta&#39;s hyperscale production cloud, enabling future Llama training to scale to tens of thousands of GPUs and beyond.</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/the-llama-3-herd-of-models/&amp;sa=D&amp;source=editors&amp;ust=1728884223256227&amp;usg=AOvVaw1ys2CnwWHL21hHRwvOFsp0">The Llama 3 Herd of Models</a></span><span class="c0">: </span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-2 start"><li class="c9 c11 li-bullet-0"><span>Our contributions include much of the work described in the paper&rsquo;s Section 3.3 </span><span class="c7">&ldquo;Infrastructure, Scaling, and Efficiency&rdquo; , </span><span>Section 6 &ldquo;</span><span class="c7">Inference</span><span>&rdquo;, and Section 7.3</span><span class="c7">&nbsp;&ldquo;Model Scaling.&rdquo;</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2104.05158&amp;sa=D&amp;source=editors&amp;ust=1728884223256587&amp;usg=AOvVaw1fBAVADjbcR4NnLJ_1UF-7">Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2304.11277&amp;sa=D&amp;source=editors&amp;ust=1728884223256755&amp;usg=AOvVaw05HA8B5xSXEYOmCmkxVxN1">PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">ML models and kernels</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/1906.00091&amp;sa=D&amp;source=editors&amp;ust=1728884223256945&amp;usg=AOvVaw0dlT0imhKOUCFcUuNC4H0t">Deep Learning Recommendation Model for Personalization and Recommendation Systems</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.02545&amp;sa=D&amp;source=editors&amp;ust=1728884223257090&amp;usg=AOvVaw1SwQCVOGqZhB4_58gb9uu6">Wukong: Towards a Scaling Law for Large-Scale Recommendation</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2101.05615&amp;sa=D&amp;source=editors&amp;ust=1728884223257230&amp;usg=AOvVaw00hpq_qHon0IDw9X7no-eX">FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">ML numerics, pruning, distillation, and optimizer</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.10537&amp;sa=D&amp;source=editors&amp;ust=1728884223257421&amp;usg=AOvVaw1vWH2MygZXFrfXWQmMx5x8">Microscaling Data Formats for Deep Learning</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://pytorch.org/blog/int4-decoding/&amp;sa=D&amp;source=editors&amp;ust=1728884223257567&amp;usg=AOvVaw2lzXS-G4JohH6W8ge9C6iP">INT4 Decoding GQA CUDA Optimizations for LLM Inference</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/&amp;sa=D&amp;source=editors&amp;ust=1728884223257730&amp;usg=AOvVaw2eAILRFPl13qppVJ2JIHj4">Pruning and Distillation to Enable Llama 3.2 1B and 3B Models Suitable for Mobile Devices</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.linkedin.com/posts/hjmshi_announcing-the-results-of-the-inaugural-algoperf-activity-7224879495734870017-rVHn/&amp;sa=D&amp;source=editors&amp;ust=1728884223257919&amp;usg=AOvVaw3moUiQXLYHhIEXPwTlN4US">PyTorch Distributed Shampoo Winning the MLCommon Training Algorithms Competition</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">HPC and collective communications library (MPI, NCCL, RCCL)</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.04272&amp;sa=D&amp;source=editors&amp;ust=1728884223258152&amp;usg=AOvVaw2kCi5rS8ey6hxXzAwTS7q7">Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2020/08/Training-Deep-Learning-Recommendation-Model-with-Quantized-Collective-Communications-v2.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223258386&amp;usg=AOvVaw3oZ0cxg_FlIC6ea2OaWHlC">Training Deep Learning Recommendation Model with Quantized Collective Communications</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">Performance benchmarking and projection</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728884223258631&amp;usg=AOvVaw2d0lARt0sGkzBlCl52JCd8">DCPerf: An open source benchmark suite for hyperscale compute applications</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/&amp;sa=D&amp;source=editors&amp;ust=1728884223258800&amp;usg=AOvVaw39gx63De5p4jt7Uo1OnxOz">DLRM: An advanced, open source deep learning recommendation model</a></span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c0">Hardware and software co-design</span></li></ul><ul class="c8 lst-kix_c3m3d4lhbmd7-1 start"><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2206.02878&amp;sa=D&amp;source=editors&amp;ust=1728884223259006&amp;usg=AOvVaw3lKwMImIHk2g8H9MD4Siml">TPP: Transparent Page Placement for CXL-Enabled Tiered-Memory</a></span></li><li class="c6 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2019/05/SoftSKU-Optimizing-Server-Architectures-for-Microservice-Diversity-@Scale.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223259217&amp;usg=AOvVaw1VpBqT2aGxJHNs3G-EZJb3">SoftSKU: Optimizing Server Architectures for Microservice Diversity @Scale</a></span></li></ul><p class="c2"><span class="c0"></span></p><p class="c9"><span>For the areas mentioned above, we are actively hiring managers, PhDs, and experienced engineers, but currently we are not hiring new graduates with BS or MS degrees. If interested, please submit your resume </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://2024resumedropco-design.splashthat.com/&amp;sa=D&amp;source=editors&amp;ust=1728884223259478&amp;usg=AOvVaw3C_VJz39STQqvA8H70m7IS">here</a></span><span>. If you have questions, please email us at <br></span><span class="c7 c10 c14">codesign AT meta DOT com.</span></p><p class="c2"><span class="c0"></span></p><p class="c9"><span class="c0">Like research labs, our team consists primarily of PhDs, and we strongly encourage and excel in research publications. However, we differ from traditional research labs in several key ways:</span></p><ul class="c8 lst-kix_qu9w87i2kjte-0 start"><li class="c5 li-bullet-0"><span class="c10">Production focus: </span><span>Our primary goal is to develop forward-looking innovations in hardware, software, and AI, and directly implement them in production systems that serve billions of users. </span></li><li class="c5 li-bullet-0"><span class="c10">Direct ownership</span><span class="c0">: Like traditional research labs, we build strong partnerships with numerous teams across diverse areas for broad influence. However, what sets us apart is our direct ownership of the company&rsquo;s hardware strategy. This enables us to lead in many areas while fostering seamless partnerships in others.</span></li><li class="c5 li-bullet-0"><span class="c10">Impact</span><span>: Our impact is widely recognized across the company. We drive </span><span>Meta&rsquo;s hardware strategy to save billions of dollars, and directly develop innovative technologies in Meta&rsquo;s flagship products like Llama and Ads ranking models.</span></li></ul><p class="c2"><span class="c0"></span></p><a id="id.ntu08f6dqd4i"></a><p class="c9"><span>To gain a better understanding of who we are, feel free to explore some profiles of our team </span><span>members: </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://tangchq74.github.io/&amp;sa=D&amp;source=editors&amp;ust=1728884223260207&amp;usg=AOvVaw2NCPxb5gFHXwVWuS2jExnH">Chunqiang (CQ) Tang</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D8xbO51UAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223260349&amp;usg=AOvVaw1NnrQHSZA2YEdQiWrPu_Je">Pavan Balaji</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DHqGW4HIAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223260471&amp;usg=AOvVaw18GzOw9pQm_Os9SG4b9kBf">Amar Phanishayee</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3Dp5h2zh8AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223260583&amp;usg=AOvVaw3Zav5GS1ox3HZ0zMURJjfJ">Maxim Naumov</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://sites.google.com/site/jongsoopark/home&amp;sa=D&amp;source=editors&amp;ust=1728884223260686&amp;usg=AOvVaw12G8y7VzHKcFVl-uo8lKek">Jongsoo Park</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DeOyDnQYAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728884223260797&amp;usg=AOvVaw1I590wvfq8E9mu3Hg8L1rJ">Changkyu Kim</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DyxUD8q4AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223260907&amp;usg=AOvVaw3cT0zXE2MXET22foFpmCKN">Doe Hyun Yoon</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DyUXXPwYAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728884223261013&amp;usg=AOvVaw3FO7D2T--Bn8ZU3yFOgNxX">Satish Nadathur</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D8rbsmO0AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223261149&amp;usg=AOvVaw2qxtNnyeRGXF49iV50mLfR">Abhishek Dhanotia</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DKpnlsFwAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223261266&amp;usg=AOvVaw2leeO39Y4Fqa1WBTv4afKa">Joel Coburn</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3D6PyfjT4AAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223261380&amp;usg=AOvVaw14kRWOyzaqzsEkgKJHryvJ">Ehsan K. Ardestani</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DCe2uZUYAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223261491&amp;usg=AOvVaw0h05ii2b4RpOg28np-by2K">Bangsheng Tang</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DmD2TUGQAAAAJ%26hl%3Den%26oi%3Dao&amp;sa=D&amp;source=editors&amp;ust=1728884223261599&amp;usg=AOvVaw1UR2Z3ZKds2iFmTpZA0QRz">Mustafa Ozdal</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://jianyuhuang.com/&amp;sa=D&amp;source=editors&amp;ust=1728884223261689&amp;usg=AOvVaw0_5DEwJ8Ufp4ysW54D_fiL">Jianyu Huang</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dblp.org/pid/92/5162.html&amp;sa=D&amp;source=editors&amp;ust=1728884223261785&amp;usg=AOvVaw1xyMfAR4i8lOVLDHNzbseL">Wenyin Fu</a></span><span>, </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://scholar.google.com/citations?user%3DnFONGREAAAAJ%26hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1728884223261891&amp;usg=AOvVaw3Yvc3KKMmBETE3R1imMdlf">Jayneel Gandhi</a></span></p><h2 class="c18" id="h.r2quqn5ki81e"><span>Open Source Projects</span></h2><ul class="c8 lst-kix_tqav6y84cgtf-0 start"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728884223262199&amp;usg=AOvVaw0ZAi1i-64A3261klzkcyZR">DCPerf: An open source benchmark suite for hyperscale compute applications</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/&amp;sa=D&amp;source=editors&amp;ust=1728884223262391&amp;usg=AOvVaw285f_JULPv4eIE62f7oblI">DLRM: An advanced, open source deep learning recommendation model</a></span></li><li class="c5 li-bullet-0"><span>ML kernels: </span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728884223262536&amp;usg=AOvVaw3YdyWcI8bMAwRBdZ5DXitN">FBGEMM (Facebook GEneral Matrix Multiplication) and FBGEMM_GPU(</a></span><span class="c3 c16"><a class="c1" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728884223262613&amp;usg=AOvVaw0hM1T04gITHD4q2MsP9OTG">FBGEMM GPU Kernels Library</a></span><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://fburl.com/rcll8ztm&amp;sa=D&amp;source=editors&amp;ust=1728884223262683&amp;usg=AOvVaw0NmD1JQFZWvfAHd37Aawyz">) </a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://github.com/facebookresearch/optimizers/blob/main/distributed_shampoo/README.md&amp;sa=D&amp;source=editors&amp;ust=1728884223262843&amp;usg=AOvVaw2TDS0n8LCLleb2SXW6oe00">Pytorch distributed Shampoo optimizer</a></span></li></ul><h2 class="c18" id="h.w9asws8yn66t"><span>Selected Publications</span></h2><p class="c9"><span class="c13 c4">2024</span></p><ul class="c8 lst-kix_mqbepa7onuvy-0 start"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.21783&amp;sa=D&amp;source=editors&amp;ust=1728884223263110&amp;usg=AOvVaw3wMhSDl80xXSBbVTgxklRr">The Llama 3 Herd of Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.04272&amp;sa=D&amp;source=editors&amp;ust=1728884223263289&amp;usg=AOvVaw0dtEZVX6MU3R2DyZ1slqZ0">Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.02545&amp;sa=D&amp;source=editors&amp;ust=1728884223263435&amp;usg=AOvVaw1GXQX8srPXZ5etAYNQbFB5">Wukong: Towards a Scaling Law for Large-Scale Recommendation</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://proceedings.mlsys.org/paper_files/paper/2024/file/78834433edc3291f4c6cbbd2759324db-Paper-Conference.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223263617&amp;usg=AOvVaw1WU3ZK_jRE9NgeC0RDi6pS">Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large Scale Recommendation</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.linkedin.com/posts/hjmshi_announcing-the-results-of-the-inaugural-algoperf-activity-7224879495734870017-rVHn/&amp;sa=D&amp;source=editors&amp;ust=1728884223263806&amp;usg=AOvVaw27qO5ndyjN5XLDyqgES1mQ">PyTorch Distributed Shampoo Winning the MLCommon Training Algorithms Competition</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.1145/3589335.3648304&amp;sa=D&amp;source=editors&amp;ust=1728884223263967&amp;usg=AOvVaw3p9L_FGEB6XD3nOixt7Slq">Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.14377&amp;sa=D&amp;source=editors&amp;ust=1728884223264166&amp;usg=AOvVaw0Z5TGaLlAoV_Sdy_eg6ICF">CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.usenix.org/system/files/osdi24-choudhury.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223264382&amp;usg=AOvVaw3FGkYPfjzSuhmmeB8PwQgk">MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.usenix.org/system/files/nsdi24-matam.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223264546&amp;usg=AOvVaw2HJj8H5yzWm9watLu1_9c0">QuickUpdate: a Real-Time Personalization System for Large-Scale Recommendation Model</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3640457.3688037&amp;sa=D&amp;source=editors&amp;ust=1728884223264690&amp;usg=AOvVaw3XW0lWdvdPHFmQVUIo6-ax">Toward 100TB Recommendation Models With Embedding Offloading</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2024/08/05/data-center-engineering/dcperf-open-source-benchmark-suite-for-hyperscale-compute-applications/&amp;sa=D&amp;source=editors&amp;ust=1728884223264881&amp;usg=AOvVaw3ujUFIzFAbdzR03dYONS2Y">DCPerf: An open source benchmark suite for hyperscale compute applications </a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3617232.3624853&amp;sa=D&amp;source=editors&amp;ust=1728884223265029&amp;usg=AOvVaw3DCkWeey0Huc3MIahGbJko">Expanding Datacenter Capacity with DVFS Boosting: A safe and scalable deployment experience</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.1145/3589335.3648304&amp;sa=D&amp;source=editors&amp;ust=1728884223265198&amp;usg=AOvVaw1U3dSb_58ogFvGJoExedNZ">Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale</a></span></li></ul><p class="c2"><span class="c4 c13"></span></p><p class="c9"><span class="c4">2023</span></p><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=http://firoozshahian.com/publications/3579371.3589348.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223265491&amp;usg=AOvVaw1eyqExMagM4p1kc5pTiAoM">MTIA: First Generation Silicon Targeting Meta&rsquo;s Recommendation Systems</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.10537&amp;sa=D&amp;source=editors&amp;ust=1728884223265642&amp;usg=AOvVaw1hR4WNnrYnh_N4IhmN_mP8">Microscaling Data Formats for Deep Learning</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/2302.08007&amp;sa=D&amp;source=editors&amp;ust=1728884223265779&amp;usg=AOvVaw3Sp7SbuU3KPN5ZqlZssUOZ">Shared Microexponents: A Little Shifting Goes a Long Way</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2206.02878&amp;sa=D&amp;source=editors&amp;ust=1728884223265915&amp;usg=AOvVaw3ER3vs7EG-SnnYRhoQBG6O">TPP: Transparent Page Placement for CXL-Enabled Tiered-Memory</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3579371.3589079&amp;sa=D&amp;source=editors&amp;ust=1728884223266059&amp;usg=AOvVaw1q9TPKlUBQd0DI34uREzp9">Contiguitas: The Pursuit of Physical Memory Contiguity in Datacenters</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3579371.3589072&amp;sa=D&amp;source=editors&amp;ust=1728884223266212&amp;usg=AOvVaw3HdCB5Rxx5YTKkbFpFTJ6H">Mystique: Enabling Accurate and Scalable Generation of Production AI Benchmarks</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/2211.05239&amp;sa=D&amp;source=editors&amp;ust=1728884223266366&amp;usg=AOvVaw1RMiCPOELDDjZPxIkbnZln">RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.usenix.org/conference/osdi23/presentation/lai&amp;sa=D&amp;source=editors&amp;ust=1728884223266517&amp;usg=AOvVaw1lep0riXiy5T4LS9MzyylS">AdaEmbed: Adaptive Embedding for Large-Scale Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&amp;sa=D&amp;source=editors&amp;ust=1728884223266689&amp;usg=AOvVaw2OhDz7eeJdUDzBVJbQSpJG">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/document/10158161&amp;sa=D&amp;source=editors&amp;ust=1728884223266827&amp;usg=AOvVaw1oUvGn_UYlcTYd4N60S1Vd">Characterization of Data Compression in Datacenters, </a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/3575693.3575751&amp;sa=D&amp;source=editors&amp;ust=1728884223266964&amp;usg=AOvVaw06ALr_nwDOlFrsU-CDMQE5">Ditto: End-to-End Application Cloning for Networked Cloud Services,</a></span><span class="c0">&nbsp;</span></li></ul><p class="c2"><span class="c13 c4"></span></p><p class="c9"><span class="c4">2022</span></p><ul class="c8 lst-kix_5h1v5tj214r7-0 start"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&amp;sa=D&amp;source=editors&amp;ust=1728884223267221&amp;usg=AOvVaw3hzY8XgMI0y6GQ6ALEirxm">Llama 2: Open foundation and fine-tuned chat models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2104.05158&amp;sa=D&amp;source=editors&amp;ust=1728884223267388&amp;usg=AOvVaw2LCwvV_vFVzXR0K_C7q5YN">Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2203.11014&amp;sa=D&amp;source=editors&amp;ust=1728884223267554&amp;usg=AOvVaw3r9o2jjMvH3TLLnGkqLz9h">DHEN: A deep and hierarchical ensemble network for large-scale click-through rate prediction</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://tangchq74.github.io/TMO-ASPLOS22.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223267700&amp;usg=AOvVaw3OY-Qwn_FyilZR_FVUWZNs">TMO: Transparent Memory Offloading in Datacenters</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.lockshaw.io/static/unity.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223267872&amp;usg=AOvVaw2VfQRRLsYF9wP_fYFZnsrk">Unity: A Unified Graph Representation and Runtime for Distributed DNN Training</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.usenix.org/system/files/nsdi22-paper-eisenman.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223268094&amp;usg=AOvVaw12dJIdM4wskf4KHUpAyh4z">Check-N-Run: a Checkpointing System for Training Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/9912130&amp;sa=D&amp;source=editors&amp;ust=1728884223268307&amp;usg=AOvVaw3SfqzoIVxww4r0ZgRVEhG6">Supporting Massive DLRM Inference through Software Defined Memory</a></span></li></ul><p class="c2"><span class="c0"></span></p><p class="c9"><span class="c4">2021</span></p><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2101.05615&amp;sa=D&amp;source=editors&amp;ust=1728884223268649&amp;usg=AOvVaw24JpOZBthWQpSYye61cZ7A">FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/9435938&amp;sa=D&amp;source=editors&amp;ust=1728884223268869&amp;usg=AOvVaw2K6pft2Llan9NEkt9E73wr">Low-Precision Hardware Architectures Meet Recommendation Model Inference at Scale</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/2103.00130&amp;sa=D&amp;source=editors&amp;ust=1728884223269049&amp;usg=AOvVaw1JbrUrPpMUzSkHHBs7cpac">Efficient Soft-Error Detection for Low-precision Deep Learning Recommendation Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/2107.04140.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223269237&amp;usg=AOvVaw23pBH3jTbM3WV-BtuavAue">First-Generation Inference Accelerator Deployment at Facebook</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/stamp/stamp.jsp?tp%3D%26arnumber%3D9390361&amp;sa=D&amp;source=editors&amp;ust=1728884223269456&amp;usg=AOvVaw0PE7uJX-HMNyVCuK0gSXIa">Understanding Acceleration Opportunities at Hyperscale</a></span><span class="c0">, </span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://www.usenix.org/conference/atc21/presentation/kassa&amp;sa=D&amp;source=editors&amp;ust=1728884223269708&amp;usg=AOvVaw1_YH1A-2o3YhpsIGnb80Ed">Improving Performance of Flash Based Key-Value Stores Using Storage Class Memory as a Volatile Memory Extension,</a></span></li></ul><p class="c2"><span class="c0"></span></p><p class="c9"><span class="c4">2020</span></p><ul class="c8 lst-kix_m0x3ng30pxgy-0 start"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2020/08/Training-Deep-Learning-Recommendation-Model-with-Quantized-Collective-Communications-v2.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223270096&amp;usg=AOvVaw0zsMJVTdyKiZaf5cG0i7U0">Training Deep Learning Recommendation Model with Quantized Collective Communications</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/2010.11305&amp;sa=D&amp;source=editors&amp;ust=1728884223270283&amp;usg=AOvVaw3XNLrNqXbab4JQWmzYMLtV">Mixed-Precision Embedding Using a Cache</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2020/11/18/open-source/fiosynth/&amp;sa=D&amp;source=editors&amp;ust=1728884223270453&amp;usg=AOvVaw2W8bfJ3icVuiRM4bSpo6CR">FioSynth: A representative I/O benchmark and data visualizer for data center workloads,</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://engineering.fb.com/2020/05/11/data-center-engineering/accelerometer-and-softsku/&amp;sa=D&amp;source=editors&amp;ust=1728884223270624&amp;usg=AOvVaw3wDXfS1vwBLC0qvYobzJBs">Accelerometer and SoftSKU: Improving hardware platform performance for diverse microservices</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/publications/accelerometer-understanding-acceleration-opportunities-for-data-center-overheads-at-hyperscale/&amp;sa=D&amp;source=editors&amp;ust=1728884223270816&amp;usg=AOvVaw3u_nWOA0gZzwsDjtVgDZK3">Accelerometer: Understanding Acceleration Opportunities for Data Center Overheads at Hyperscale</a></span></li></ul><p class="c2"><span class="c13 c4"></span></p><p class="c9"><span class="c4">2019</span></p><ul class="c8 lst-kix_c3m3d4lhbmd7-0"><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/pdf/1906.00091&amp;sa=D&amp;source=editors&amp;ust=1728884223271105&amp;usg=AOvVaw2GXEatmnrVHdLvY8utGfVD">Deep Learning Recommendation Model for Personalization and Recommendation Systems</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/wp-content/uploads/2019/05/SoftSKU-Optimizing-Server-Architectures-for-Microservice-Diversity-@Scale.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223271447&amp;usg=AOvVaw1kzk57BK57ziN0hd9QBYfT">SoftSKU: Optimizing Server Architectures for Microservice Diversity @Scale</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/1905.12322&amp;sa=D&amp;source=editors&amp;ust=1728884223271665&amp;usg=AOvVaw0JzCKQYcQjiNIZDkQaj0Zd">A Study of BFLOAT16 for Deep Learning Training</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://arxiv.org/abs/1911.02079&amp;sa=D&amp;source=editors&amp;ust=1728884223271821&amp;usg=AOvVaw2EnxUIF4Lk6JG7kqnqQkUX">Post-Training 4-bit Quantization of Embedding Tables</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://proceedings.mlsys.org/paper_files/paper/2019/file/d59a1dc497cf2773637256f50f492723-Paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1728884223272001&amp;usg=AOvVaw14bfVxq_NJD-H9Ycvz-fg9">Bandana: Using Non-Volatile Memory for Storing Deep Learning Models</a></span></li><li class="c5 li-bullet-0"><span class="c3"><a class="c1" href="https://www.google.com/url?q=https://research.fb.com/publications/whos-afraid-of-uncorrectable-bit-errors-online-recovery-of-flash-errors-with-distributed-redundancy/&amp;sa=D&amp;source=editors&amp;ust=1728884223272204&amp;usg=AOvVaw2O6y-65zOLO54RF2FaW5Fm">Who&#39;s Afraid of Uncorrectable Bit Errors? Online Recovery of Flash Errors with Distributed Redundancy</a></span></li></ul><div><p class="c2"><span class="c0"></span></p></div></body></html>